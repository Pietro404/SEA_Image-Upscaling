Caratteristiche principali:

Un thread CUDA per pixel di output

Mappatura diretta:
(blockIdx, threadIdx) -> (x, y) del pixel upscalato

Accessi diretti alla memoria globale
Nessun uso di shared memory

Kernel separati per:
Nearest Neighbor
Bilinear
Bicubic

Ogni thread:
calcola la posizione sorgente (src_x, src_y)
legge i pixel necessari dalla memoria globale
scrive il pixel risultante in output


Dettaglio della configurazione della griglia e della gestione della memoria.

---

## 1. Configurazione di Griglia e Blocchi

Il codice utilizza una gerarchia a due dimensioni (2D) sia per i blocchi che per la griglia. Questo è l'approccio standard per l'elaborazione di immagini, poiché permette di mappare direttamente le coordinate  dei pixel ai thread.

- Blocchi definiti come "dim3 block(16, 16);" -> Ogni blocco contiene  thread.
- Griglia calcolata in base alle dimensioni dell'immagine di output (new_width, new_height):
  grid.x = (new_width + block.x - 1) / block.x
  grid.y = (new_height + block.y - 1) / block.y



=> Mappatura Spaziale: poiché un'immagine è una matrice bidimensionale, usare blockIdx.x/y e threadIdx.x/y semplifica il calcolo dell'indice del pixel

=> Copertura Totale: la formula utilizzata per la griglia è una "divisione per eccesso".
Serve a garantire che, se la dimensione dell'immagine non è un multiplo esatto di 16, ci siano abbastanza blocchi per coprire i pixel rimanenti (i thread in eccesso vengono poi bloccati dall'istruzione di controllo:
  if (x >= new_width || y >= new_height) return;)

=> Efficienza Hardware: un blocco di 256 thread è un buon compromesso per massimizzare l'occupazione delle unità computazionali (SM) sulla maggior parte delle GPU NVIDIA.

---

## 2. Tipo di accesso alla memoria

Il codice utilizza esclusivamente la Memoria Globale (VRAM).
Non viene fatto uso di Shared Memory o Texture Memory (quest'ultima non affrontata).

Caratteristiche dell'accesso:

- Scrittura (Output) coalescente (Coalesced):
i thread appartenenti allo stesso warp (= gruppo di 32 thread consecutivi) accedono a pixel contigui nell'immagine di output.
Poiché l'indice calcolato è (y * new_width + x), quando "x" aumenta di 1 (thread adiacenti), l'indirizzo di memoria aumenta di 1 unità (poi moltiplicato per i canali).
Questo permette all'hardware di raggruppare molteplici richieste di scrittura in un'unica transazione di memoria, massimizzando la banda passante.

- Lettura (Input) *non* perfettamente coalescente (Random?).
nel ridimensionamento (scaling), l'indice di lettura "src_x" e "src_y" dipende da un rapporto ("x_ratio").
  -> In un upscaling (es. mul = 4), più thread leggono lo stesso pixel di input => accesso ridondante.
Gli indici calcolati non sono necessariamente contigui o allineati tuttavia, grazie alla cache L1/L2 delle GPU moderne, l'impatto negativo è parzialmente mitigato.


=> Semplicità: l'accesso diretto alla memoria globale è il più semplice da implementare.
=> Natura dell'algoritmo: nelle versioni Nearest Neighbor e Bilineare non c'è una forte condivisione di dati tra thread vicini che giustifichi l'uso della Shared Memory che aumenterebbe notevolmente la complessità. Nella versione bicubica invece, dove si leggono pixel vicini, è possibile usare la Shared Memory con un guadagno in termini di efficienza.
